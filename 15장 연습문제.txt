15장 연습문제

1. 시퀀스-투-시퀀스 RNN을 사용한 애플리케이션에는 어떤 것들이 있나요? 시퀀스-투-
벡터 RNN과 벡터-투-시퀀스 RNN은 어떤가요?
 : 다음은 몇 가지 RNN 애플리케이션의 사례입니다,

- 시퀀스-투-시퀀스 RNN : 날씨 예측(또는 다른 시계열 관련 문제), 시계 번역(인코더-디코더 구조 사용),
비디오 캡션 생성, 스피치 투 텍스트, 음악 생성(또는 다른 스퀀스 생성), 노래의 화음 식별

- 시퀀스-투-벡터 RNN : 음악 샘플을 장르로 구분하기, 책 후기에 대한 감성 분석, 뇌에 심은 인공칩에서
읽은 데이터를 기반으로 실어증 환자가 생각하는 단어 예측하기, 사용자의 영화 시청 이력을 바탕으로
보고 싶어 할 영화의 확률 예측하기(이는 추천 시스템을 위해 구현 가능한 협업 필터링 애플리케이션 중
하나입니다)

- 벡터-투-시퀀스 RNN : 이미지 캡션 생성, 현재 아티스티를 기반으로 음악 플레이리스트 생성, 일련의
파라미터를 기반으로 한 멜로디 생성, 사진(예를 들면 자율주행 자동차의 카메라에서 찍은 동영상 프레
임) 속에서 보행자 위치 찾기

2. RNN층의 입력은 얼마나 많은 차원을 가지나요? 각 차원이 표현하는 것은 무엇인가요?
출력은 어떤가요?
 : RNN 층의 입력 차원은 3개입니다. 첫 번째 차원은 배치 차원입니다(첫 번째 차원의 크기는 
배치 크기입니다). 두 번째 차원은 시간을 나타냅니다(두 번째 차원의 크기는 타임 스텝의
개수입니다). 세 번째 차원에는 타임 스텝마다 입력을 담고 있습니다(세 번째 차원의 크기는
입력 특성의 개수입니다). 예를 들어 2개의 값(예를 들어 온도와 풍속)을 가진 타임 스텝 10개로
이루어진 시계열 5개를 담은 배치를 처리한다면 이 배치의 크기는 [5, 10, 2]가 됩니다. 출력
차원도 3개입니다. 처음 두 개 차원은 입력과 동일하고 마지막 차원은 뉴런의 개수입니다.
예를 들어 뉴런 32개를 가진 RNN 층이 앞서 언급한 배치를 처리한다면 출력 크기는 [5, 10, 32]
가 됩니다.

3. 심층 시퀀스-투-시퀀스 RNN을 만든다면 어떤 RNN 층을 return_sequences=True로
설정해야 하나요? 시퀀스-투-벡터 RNN은 어떤가요?
 : 케라스로 심층 시퀀스-투-시퀀스 RNN을 만들려면 모든 RNN 층에 return_sequences=True를
설정해야 합니다. 시퀀스-투-벡터 RNN을 만들려면 최상위 RNN 층을 제외한 모든 RNN 층에
return_sequences=True를 설정해야 합니다. 최상위 RNN 층은 return_sequences=False로 지정합니다.
(또는 False가 기본값이기 때문에 이 매개변수를 지정하지 않습니다).

4. 일자별 단변량 시계열 데이터를 가지고 다음 7일을 예측하려고 합니다. 어떤 RNN 구조를
사용해야 하나요?
 : 일자별 단변량 시계열 데이터가 있고 다음 7일을 예측하려면 사용할 수 있는 가장 간단한
RNN 구조는 (최상위 RNN 층을 제외하고 모두 return_sequences=True로 설정한) RNN 층을
쌓아올리는 것입니다. 출력 RNN 층에는 뉴런 7개를 사용합니다. 그다음 이 모델을 시계열에
랜덤한 윈도우를 적용해 훈련합니다(예를 들어 연속된 30일 시퀀스를 입력으로 사용하고 다음
7일의 값을 담은 벡터를 타깃으로 사용합니다). 이는 시퀀스-투-벡터 RNN입니다. 또 다른
방법은 스퀀스-투-시퀀스 RNN을 만들기 위해 모든 RNN 층에 return_sequences=True를
설정하는 것입니다. 이 모델을 시계열에 랜덤한 윈도우를 적용해 훈련합니다. 이때 입력과
타깃에 동일한 길이의 시퀀스를 사용합니다. 각 타깃 시퀀스는 타임 스텝마다 7개의 값을
가집니다(예를 들어 타임 스텝 t에서 타깃은 타임 스텝 t+1에서 t+7까지 값을 담은 벡터입니다).

5. RNN을 훈련할 때 주요 문제는 무엇인가요? 어떻게 이를 처리할 수 있나요?
 : RNN을 훈련할 때 발생하는 주요 문제는 불안정한 그레이디언트(그레이디언트 폭주 또는
소실)와 제한적인 단기 기억입니다. 긴 시퀀스를 다룰 때 이 문제는 더욱 심각해집니다.
불안정한 그레이디언트 문제를 줄이기 위해 더 작은 학습률을 사용하거나, 하이퍼볼릭
탄젠트(기본값)와 같이 수렴하는 활성화 함수를 사용하거나, 그레이디언트 클리핑, 층 정규화,
타임 스텝마다 드롭아웃을 사용할 수 있습니다. 제한적인 단기 기억 문제를 해결하기 위해
LSTM이나 GRU 층을 사용할 수 있습니다(불아정한 그레이디언트 문제에도 도움이 됩니다).

6. LSTM 셀의 구조를 그릴 수 있나요?
 : LSTM 셀 구조는 복잡해 보이지만 내부 로직을 이해하고 나면 실제로 너무 어렵지 않습니다.
셀은 단기 상태 벡터와 장기 상태 벡터를 가집니다. 각 타임 스텝에서 입력과 이전 단기
상태가 간단한 RNN 셀과 세 개의 게이트로 주입됩니다. 삭제 게이트는 장기 상태에서 삭제될
것을 결정합니다. 입력 게이트는 RNN 셀의 출력의 어느 부분이 장기 상태에 추가 되어야
하는지 결정합니다. 출력 게이트는 장기 상태의 어느 부분이 (tanh 활성화 함수를 거쳐) 매
타임 스텝마다 출력되어야 하는지 결정합니다. 새로운 단기 상태는 셀의 출력과 같습니다.

7. 왜 RNN 안에 1D 합성곱 층을 사용해야 하나요?
 : RNN 층은 근본적으로 순차적입니다. 타임 스텝 t에서 출력을 계산하기 위해 먼저 모든 이전
타임 스텝의 출력을 계산해야 합니다. 이런 방식은 병렬화하지 못합니다. 반면 1D 합성곱
층은 타임 스텝 간에 상태를 유지하기 않기 때문에 병렬화가 쉽습니다. 다른 말로 하면 메모리가
없습니다. 어떤 타임 스텝에서 출력은 이전의 모든 값을 알 필요 없이 입력에 적용된 작은 
윈도우를 기반으로 계산됩니다. 또한 1D 합성곱 층은 순환 층이 아니므로 불안정한 그레이디언트
의 영향을 덜 받습니다. RNN에 하나 이상의 1D 합성곱 층을 사용하여 입력을 효율적으로 전처리
할 수 있습니다. 예를 들어 시간 방향 해상도를 줄여(다운샘플링하여) RNN 층이 장기 패턴을
감지하는 데 도움이 됩니다. 사실 WaveNet 구조처럼 1D 합성곱 층만 사용할 수 있습니다.

8. 영상을 분류하기 위해 어떤 신경망 구조를 사용할 수 있나요?
 : 화면 내용을 기초로 동영상을 분류하려면 (예를 들어) 초당 한 프레임을 받아 각 프레임을
합성곱 신경망(예를 들어 데이터셋이 너무 크지 않다면 가중치를 동결한 사전 훈련된 Xception
모델)에 통과시키고 이 CNN의 출력 시퀀스를 시퀀스-투-벡터 RNN에 주입하고 마지막에
소프트맥스 층을 통과시켜 모든 클래스에 대한 확률을 구하는 구조를 생각해 볼 수 있습니다.
훈련을 위해서는 크로스 엔트로피를 비용 함수로 사용하면 됩니다. 분류에 오디오도 사용하려면
스트라이드 1D 합성곱 층을 쌓아 초당 수천 개의 오디오 프레임을 초당 하나로 시간 방향
해상도를 줄일 수 있습니다(초당 이미지 개수에 맞춥니다). 그리고 이 출력을 (마지막 차원을
따라) 시퀀스-투-벡터 RNN의 입력에 연결합니다.