17장 연습문제

1.오토인코더를 활용할 수 있는 주요 작업은 무엇인가요?
 : 특성 추출, 비지도 사전훈련, 차원 축소, 생성 모델, 이상치 탐색(일반적으로 오토인코더는
이상치를 재구성하는 일은 잘하지 못합니다.)

2. 레이블되지 않은 훈련 데이터는 많지만, 레이블된 데이터는 수천 개 정도만 가지고 있을 때 
분류기를 훈련하려 합니다. 오토인코더가 어떻게 도움이 될 수 있을까요? 어떻게 작업하면 될까요?
 : 레이블되지 않은 훈련 데이터는 많지만, 레이블된 데이터는 수천 개 정도만 가지고 있을 때
분류기를 훈련시키려면 전체 데이터셋(레이블된 것 + 레이블되지 않은 것)에 먼저 심층 오토인코더를
훈련시킨 다음 하위층 절반(즉, 코딩 층과 그 하위층들, 인코딩층)을 재사용합니다. 그리고 레이블된
데이터를 사용해 분류기를 훈련시킵니다. 레이블된 데이터가 조금밖에 없다면 분류기를 훈련시킬 때
재사용된 층을 동결하는 것이 좋습니다.

3. 오토인코더가 완벽하게 입력을 재구성했다면, 이것이 반드시 좋은 오토인코더인가요?
오토인코더의 성능을 어떻게 평가할 수 있나요?
 : 어떤 오토인코더가 입력을 완벽하게 재구성한다는 사실이 반드시 좋은 오토인코더임을
의미하는 것은 아닙니다. 아마도 입력을 코딩 층과 출력으로 복사하는 것을 배운 과대완전
오토인코더일지 모릅니다. 사실 코딩 층의 뉴런이 한 개여도 매우 깊은 오토인코더는 모든
훈련 샘플을 다른 코딩으로 매핑하는 것이 가능합니다(예를 들어 첫 번째 샘플은 0.001에,
두 번째 샘플은 0.002에, 세 번째 샘플은 0.003에 매핑되는 식입니다). 그리고 각 코딩에 대한
정확한 훈련 샘플을 재구성하는 것을 외워서 학습할 수 있습니다. 데이터에 있는 어떤 유용한
패턴을 실제 학습하지 않고 입력을 완벽히 재구성합니다. 실전에서 이런 매핑은 거의 일어나지
않지만 완벽하게 재구성되었다는 것이 오토인코더가 유용한 어떤 것을 학습했다고 보장하지
않는다는 사실을 말해줍니다. 하지만 재구성이 매우 나쁘다면 좋지 못한 오토인코더임이 거의
틀림없습니다. 오토인코더의 성능을 재기 위한 한 가지 방법은 재구성 손실을 계산하는 것입니다(
예를 들어 출력에서 입력을 뺀 값의 평균 제곱인 MSE를 계산합니다). 여기에서도 높은 재구성
손실은 오토인코더가 나쁘다는 것을 알려주는 좋은 신호입니다. 하지만 재구성 손실이 낮다고
해서 좋은 오토인코더임을 보장할 수는 없습니다. 사용하는 방식에 맞추어 오토인코더를
평가해야 합니다. 예를 들어 분류기의 비지도 사전훈련을 위해 사용한다면 분류기의 성능도
반드시 평가해야 합니다.

4. 과소완전과 과대완전 인코더가 무엇인가요? 지나치게 과소완전인 오토인코더의 주요한
위험은 무엇인가요? 과대완전 오토인코더의 주요한 위험은 무엇인가요?
 : 과소완전 오토인코더는 코딩 층이 입력층과 출력층보다 작은 경우입니다. 만약 코딩 층이
더 크다면 과대완전 오토인코더입니다. 아주 심한 과소완전 오토인코더는 입력을 재구성하는
데 실패할 가능성이 큽니다. 과대완전 오토인코더의 주된 문제는 유용한 특성을 학습하지 못하고
입력을 출력으로 그냥 복사하는 것입니다.

5. 적층 오토인코더의 가중치를 어떻게 묶나요? 이렇게 하는 이유는 무엇인가요?
 : 인코더 층의 가중치를 그에 상응하는 디코더 층과 묶으려면 인코더 가중치의 전치를 디코더의
가중치로 사용하면 됩니다. 이렇게 하면 모델의 파라미터 개수가 반으로 줄고, 종종 적은 훈련
데이터로도 수렴이 빨라집니다. 또한 훈련 세트에 과대적합될 위험을 감소시킵니다.

6. 생성 모델이 무엇인가요? 생성 오토인코더의 종류를 말할 수 있나요?
 : 생성 모델은 훈련 샘플과 닮은 출력을 랜덤하게 생성할 수 있는 모델입니다. 예를 들어 MNIST
데이터셋에 잘 훈련된 생성 모델은 실제와 같은 임의의 숫자 이미지를 생성할 수 있습니다. 출력
분포는 일반적으로 훈련 데이터와 비슷합니다. 예를 들어 MNIST에는 각 숫자별 이미지가 많기
때문에 이 생성 모델은 각 숫자에 대해 거의 비슷한 개수의 미지를 출력할 것입니다. 어떤 생성
모델은 특정 종류의 출력만 생성하기 위해 파라미터로 제어할 수 있습니다. 변이형 오토인코더가
생성 오토인코더의 한 예입니다.

7. GAN이 무엇인가요? GAN이 유용한 몇 가지 작업을 나열할 수 있나요?
 : 생성적 적대 신경망은 서로 반대 목적을 가진 생성자와 판별자 두 부분으로 구성된 신경망 구조입니다.
생성자의 목표는 훈련 세트에 있는 샘플과 비슷한 샘플을 생성하여 판별자를 속이는 것입니다. 판별자는
진짜 샘플과 생성된 샘플을 구별해야 합니다. 훈련 반복마다 판별자를 보통 이진 분류기처럼 훈련합니다.
그다음 생성자를 판별자의 오류가 최대가 되도록 훈련합니다. 초해상도, 컬러 바꾸기, 이미지 편집(실제
같은 배경으로 바꾸기), 간단한 스케치를 실제 같은 이미지로 바꾸기, 동영상에서 다음 프레임 예측하기와
같은 고급 이미지 처리 작업에 GAN을 사용합니다. 또한 (다른 모델을 훈련하기 위한) 데이터 증식, (텍스트,
오디오, 시계열 같은) 여러 다른 종류의 데이터 생성, 다른 모델의 취약점을 식별하고 개선하기 등에
널리 사용합니다.

8. GAN을 훈련할 때 주요 어려움은 무엇인가요?
 : GAN은 훈련하기 어렵기로 유명합니다. 생성자와 판별자 사이의 복잡한 역학 관계 때문입니다.
가장 큰 문제점은 생성자가 다양하지 않은 출력을 만드는 모드 붕괴입니다. 또한 훈련이 매우
불안정할 수 있습니다. 처음에 안정되게 시작했지만 특별한 이유 없이 갑자기 진동하거나 발산할
수 있습니다. 또한 GAN은 하이퍼파라미터 선택에 매우 민감합니다.
 